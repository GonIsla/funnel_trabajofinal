{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importamos los paquetes necesarios\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cargamos los datos\n",
    "start_base = pd.read_csv('C:\\\\Users\\\\OLX - Gonzalo\\\\Desktop\\\\tesis\\\\FIM_s_before.csv', sep = ',', usecols = [1,2])\n",
    "not_s_base = pd.read_csv('C:\\\\Users\\\\OLX - Gonzalo\\\\Desktop\\\\tesis\\\\FIM_not_s.csv', sep = ',', usecols = [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Unimos las columnas por itemsets iguales, solo interesan las de starters\n",
    "\n",
    "#Primero renombro las columnasa diferentes\n",
    "not_s_base = not_s_base.rename(index=str, columns = {'support':'support_not_s', 'itemsets':'itemsets'})\n",
    "\n",
    "#ahora si haciendo left a los starters\n",
    "\n",
    "base = pd.merge(start_base, not_s_base, how = 'left', on=['itemsets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculamos el lift y nos quedamos con los de lift > 1\n",
    "\n",
    "#completamos los na con un valor menor al min support\n",
    "base.fillna(value = 0.0001)\n",
    "\n",
    "#dividimos los dos support \n",
    "base['lift'] = base['support']/base['support_not_s']\n",
    "\n",
    "#separamos solo los itemset que tiene lift >1\n",
    "base_lift = base[base['lift']>1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transformo la columna de itemsets que esta en strings a lista de integers\n",
    "itemsets_series = base_lift['itemsets'].apply(lambda x: x.strip(\"[]\").replace(\"'\", \"\").replace(\" \", \"\").split(\",\"))\n",
    "itemsets_series = itemsets_series.apply(lambda x: [int(v_list) for v_list in x]) \n",
    "base_lift.pop('itemsets')\n",
    "base_lift = pd.concat([base_lift,itemsets_series],axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Funcion de distancias\n",
    "\n",
    "https://scholarscompass.vcu.edu/cgi/viewcontent.cgi?referer=&httpsredir=1&article=1037&context=cmsc_pubs\n",
    "\n",
    "FunciÃ³n de distancias si es 0 son iguales, si es 1 son completamente distintos\n",
    "\n",
    "D = alfa * d1 + (1-alfa) * d2\n",
    "\n",
    "d1 = 1 - [Cantidad de eventos iguales entre I1 e I2] / [Cantidad de eventos diferentes en los dos patrones ]\n",
    "\n",
    "\n",
    "d2 = {Si no hay eventos iguales entre los patrones --> 1,\n",
    "\n",
    "    Si hay al menos 1 evento igual -->\n",
    "    \n",
    "    SUMA[para los eventos iguales entre I1 e I2]\n",
    "    \n",
    "    ([Ocurrencia del evento en el data set] / \n",
    "    \n",
    "    SUMA[ para los eventos diferentes entre los dos patrones ](ocurrencia de cada uno de los eventos en el dataset))}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Primero hay que saber todos los eventos diferentes a considerar\n",
    "v_itemsets = []\n",
    "for itemset in base_lift['itemsets']:\n",
    "    for event in itemset:\n",
    "        if event not in v_itemsets:\n",
    "            v_itemsets.append(event)        \n",
    "\n",
    "#v_itemsets = [int(x) for x in v_itemsets]            \n",
    "v_itemsets.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#despues hay que contar la frecuencia de cada evento en el data set\n",
    "# y construir una matriz EF que tenga ordenados: evento, frecuencia\n",
    "'''\n",
    "# cargo los dataset en tres partes y los uno\n",
    "df1 = pd.read_csv('C:\\\\Users\\\\OLX - Gonzalo\\\\Desktop\\\\tesis\\\\event_base_1.tsv', sep = '\\t')\n",
    "df2 = pd.read_csv('C:\\\\Users\\\\OLX - Gonzalo\\\\Desktop\\\\tesis\\\\event_base_2.tsv', sep = '\\t')\n",
    "df3 = pd.read_csv('C:\\\\Users\\\\OLX - Gonzalo\\\\Desktop\\\\tesis\\\\event_base_3.tsv', sep = '\\t')\n",
    "\n",
    "df_events = pd.concat([df1, df2, df3])\n",
    "\n",
    "\n",
    "basket_all = (df_events\n",
    "          .groupby(['session_fake_id', 'event_id'])['session_fake_id']\n",
    "          .count().unstack().reset_index().fillna(0)\n",
    "          .set_index('session_fake_id'))\n",
    "\n",
    "basket_all_events_freq = basket_all.sum(axis=0)\n",
    "\n",
    "del(df1)\n",
    "del(df2)\n",
    "del(df3)\n",
    "del(df_events)\n",
    "del(basket_all)\n",
    "\n",
    "basket_all_events_freq.to_csv('C:\\\\Users\\\\OLX - Gonzalo\\\\Desktop\\\\tesis\\\\basket_all_events_freq.csv') '''\n",
    "\n",
    "basket_all_events_freq = pd.read_csv('C:\\\\Users\\\\OLX - Gonzalo\\\\Desktop\\\\tesis\\\\basket_all_events_freq.csv'\n",
    "                                     , sep = ',', header = None, names = ['itemset', 'freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hacer una matriz Mfe (boolean_itemsets) que tenga una fila por itemset y una columna de 0 y 1 si tiene o no tiene el evento\n",
    "boolean_itemsets = []\n",
    "for v_list in itemsets_series:\n",
    "    boolean_serie = []\n",
    "    for v_int in v_itemsets:\n",
    "        if v_int in v_list:\n",
    "            boolean_serie.append(1)\n",
    "        else:\n",
    "            boolean_serie.append(0)\n",
    "    boolean_itemsets.append(boolean_serie)\n",
    "\n",
    "boolean_itemsets = np.array(boolean_itemsets)\n",
    "del(boolean_serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hacer una matriz MVClenght (common_itemsets) que sea una matriz de distancias con el # de eventos distintos entre cada par,\n",
    "\n",
    "common_itemsets = []\n",
    "\n",
    "for i in range(boolean_itemsets.shape[0]):\n",
    "    column_common_itemsets = []\n",
    "    for j in range(boolean_itemsets.shape[0]):\n",
    "        v_length = np.sum(np.logical_or(boolean_itemsets[i], boolean_itemsets[j])*1)\n",
    "        column_common_itemsets.append(v_length)\n",
    "    common_itemsets.append(column_common_itemsets)\n",
    "\n",
    "del(column_common_itemsets)\n",
    "del(v_length)\n",
    "\n",
    "common_itemsets = np.array(common_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hacer una matriz MVCfreq (freq_common_itemsets) que sea una matriz de distancias con el # de eventos distintos entre cada par,\n",
    "\n",
    "events_freq = np.array(basket_all_events_freq[0:boolean_itemsets.shape[1]]['freq']).T.astype(int)\n",
    "freq_common_itemsets = []\n",
    "\n",
    "for i in range(boolean_itemsets.shape[0]):\n",
    "    column_freq_itemsets = []\n",
    "    for j in range(boolean_itemsets.shape[0]):\n",
    "        v_freq = np.array(np.logical_or(boolean_itemsets[i], boolean_itemsets[j])*1).dot(events_freq)\n",
    "        column_freq_itemsets.append(v_freq)\n",
    "    freq_common_itemsets.append(column_freq_itemsets)\n",
    "\n",
    "del(column_freq_itemsets)\n",
    "del(v_freq)\n",
    "\n",
    "freq_common_itemsets = np.array(freq_common_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Matriz de distancias d1: Mfe X Mfe[T] / [MVClength] \n",
    "\n",
    "d1 = 1-(boolean_itemsets.dot(boolean_itemsets.T) / common_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerador de Matriz de distancias d2: freq de cada par comun de eventos\n",
    "\n",
    "freq_same_itemsets = []\n",
    "\n",
    "for i in range(boolean_itemsets.shape[0]):\n",
    "    column_freq_itemsets = []\n",
    "    for j in range(boolean_itemsets.shape[0]):\n",
    "        v_freq = np.array(np.logical_and(boolean_itemsets[i], boolean_itemsets[j])*1).dot(events_freq)\n",
    "        column_freq_itemsets.append(v_freq)\n",
    "    freq_same_itemsets.append(column_freq_itemsets)\n",
    "\n",
    "del(column_freq_itemsets)\n",
    "del(v_freq)\n",
    "\n",
    "freq_same_itemsets = np.array(freq_same_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Denominador matriz de distancias d2\n",
    "denom_d2 = (freq_common_itemsets * common_itemsets)\n",
    "d2 = freq_same_itemsets / denom_d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#para d2 en los casos que es uno tiene que ser cero y cuando es cero tiene que ser 1\n",
    "cambio_unos_d2 = (d2 == np.ones(d2.shape))*1.0\n",
    "cambio_ceros_d2 = (d2 == np.zeros(d2.shape))*1.0\n",
    "\n",
    "d2 = d2 - cambio_unos_d2 + cambio_ceros_d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('C:\\\\Users\\\\OLX - Gonzalo\\\\Desktop\\\\tesis\\\\matriz_dist_d1.csv', d1, '%f', delimiter = ',')\n",
    "np.savetxt('C:\\\\Users\\\\OLX - Gonzalo\\\\Desktop\\\\tesis\\\\matriz_dist_d2.csv', d2, '%f', delimiter = ',')\n",
    "itemsets_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_lift.to_csv('C:\\\\Users\\\\OLX - Gonzalo\\\\Desktop\\\\tesis\\\\base_itemsets_lift_1.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
